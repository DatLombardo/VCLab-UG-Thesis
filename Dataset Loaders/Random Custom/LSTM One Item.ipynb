{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "~~~| Custom.py Execution |~~~\n",
      "Loaded dataset\n",
      "~~~| Custom.py Complete |~~~\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU(inplace)\n",
       "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (3): ReLU(inplace)\n",
       "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (6): ReLU(inplace)\n",
       "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (8): ReLU(inplace)\n",
       "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (11): ReLU(inplace)\n",
       "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (13): ReLU(inplace)\n",
       "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (15): ReLU(inplace)\n",
       "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (18): ReLU(inplace)\n",
       "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (20): ReLU(inplace)\n",
       "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (22): ReLU(inplace)\n",
       "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (25): ReLU(inplace)\n",
       "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (27): ReLU(inplace)\n",
       "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (29): ReLU(inplace)\n",
       "  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "import Custom as CustomDataset\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\"\"\"\n",
    "Do not run this code block without cuda()\n",
    "\n",
    "Load in vgg16, \n",
    "\"\"\"\n",
    "vgg16 = models.vgg16(pretrained=True).cuda()\n",
    "#vgg16 = models.vgg16(pretrained=True)\n",
    "customDataloader = CustomDataset.main() #for dataloader\n",
    "\n",
    "for param in vgg16.parameters():\n",
    "    param.requires_grad = False\n",
    "    # Replace the last fully-connected layer\n",
    "    # Parameters of newly constructed modules have requires_grad=True by default\n",
    "vgg16_fcn = vgg16.features \n",
    "vgg16_fcn.cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataPoint(element, index):\n",
    "    scores = []\n",
    "    for frame in range(len(element['video'][index])):\n",
    "        video = element['video'][index]\n",
    "        #plt.imshow(video[frame].numpy())\n",
    "        #plt.show(block=False)\n",
    "        \n",
    "        #print(data['video'][seg][frame].shape)\n",
    "        #print(element['scores'][frame][index])\n",
    "        scores.append(int(element['scores'][frame][index]))\n",
    "    points = np.zeros((7,3), dtype=int)\n",
    "    frames = np.add(*np.indices((7, 3)))\n",
    "    if (1 in scores):\n",
    "        boundary = scores.index(1)\n",
    "        for i in range(7):\n",
    "            for j in range(3):\n",
    "                frames[i][j] = i + j\n",
    "                if (i + j == boundary):\n",
    "                    points[i][j] = 1\n",
    "    return points.tolist(), frames.tolist(), video, index\n",
    "\n",
    "def parseVideoMatrix(vid, positions):\n",
    "    vid = vid.numpy()\n",
    "    newData = np.zeros((7, 3, 3, 224,224))\n",
    "    count = 0\n",
    "    for i in positions:\n",
    "        frames = np.zeros((3, 3, 224, 224))\n",
    "        for j in range(len(i)):\n",
    "            #Models expect 3xHxW\n",
    "            #Current format before swaps, WxHx3\n",
    "            frames[j,...] = np.swapaxes(vid[i[j]], 0, 2)\n",
    "        newData[count,...] = frames\n",
    "        count += 1\n",
    "    return newData\n",
    "    \n",
    "def parseViewVids(vid, positions):\n",
    "    vid = vid.numpy()\n",
    "    newData = np.zeros((7, 3, 224, 224,3))\n",
    "    count = 0\n",
    "    for i in positions:\n",
    "        frames = np.zeros((3, 224, 224, 3))\n",
    "        for j in range(len(i)):\n",
    "            #Models expect 3xHxW\n",
    "            #Current format before swaps, WxHx3\n",
    "            frames[j,...] = vid[i[j]]\n",
    "        newData[count,...] = frames\n",
    "        count += 1\n",
    "    return newData\n",
    "\n",
    "def viewVideo(vid):\n",
    "    for i in vid:\n",
    "        for j in i:\n",
    "            plt.imshow(j)\n",
    "            plt.show(block=False)\n",
    "            \n",
    "\n",
    "\"\"\"\n",
    "Reading in data to get single batch for training\n",
    "\"\"\"\n",
    "for batch_i, data in enumerate(customDataloader): \n",
    "        for i in range(len(data['video'])):\n",
    "            currSegment = data['video'][i]\n",
    "            showFrame = data['video'][i][0]\n",
    "            #plt.imshow(showFrame.numpy())\n",
    "            #plt.show(block=False)\n",
    "            \n",
    "            batchData = data\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "scoreList, frameNums, vidData, index = getDataPoint(batchData, 3)\n",
    "dataItem = parseVideoMatrix(vidData, frameNums)\n",
    "print(scoreList)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 3, 224, 224])\n",
      "torch.Size([4, 3, 3, 224, 224])\n",
      "torch.Size([4, 3, 224, 224])\n",
      "torch.Size([4, 3, 512, 7, 7])\n",
      "torch.Size([4, 3, 25088])\n",
      "torch.Size([4, 3, 256])\n",
      "torch.Size([4, 3])\n",
      "tensor([[ 0.1549,  0.2016,  0.1307],\n",
      "        [ 0.1839,  0.1291,  0.1011],\n",
      "        [ 0.1060,  0.0818, -0.0234],\n",
      "        [ 0.0690, -0.0328, -0.2472]], grad_fn=<SqueezeBackward0>)\n",
      "torch.Size([4, 3, 512, 7, 7])\n",
      "torch.Size([4, 3, 25088])\n",
      "torch.Size([4, 3, 256])\n",
      "torch.Size([4, 3])\n",
      "tensor([[ 0.0690, -0.0328, -0.2472],\n",
      "        [-0.0291, -0.2410, -0.2251],\n",
      "        [-0.2034, -0.2088, -0.1241],\n",
      "        [-0.1392, -0.0747, -0.0169]], grad_fn=<SqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"               \n",
    "model = MyModel(512*7*7, 256)\n",
    "print(batchOne.shape)\n",
    "print(batchTwo.shape)\n",
    "print(batchOne[:,0,:,:,:].shape)\n",
    "\n",
    "out = np.squeeze(model(512*7*7, batchOne))\n",
    "print(out.shape)\n",
    "print(out)\n",
    "out2 = np.squeeze(model(512*7*7, batchTwo))\n",
    "print(out2.shape)\n",
    "print(out2)\n",
    "\"\"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "USING SIGMOID\n",
    "\"\"\"\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, inputDim, outputDim):\n",
    "        super(MyModel, self).__init__()\n",
    "        vgg16 = models.vgg16(pretrained=True)\n",
    "        #vgg16 = models.vgg16(pretrained=True).cuda()\n",
    "        for param in vgg16.parameters():\n",
    "            param.requires_grad = False\n",
    "            # Replace the last fully-connected layer\n",
    "            # Parameters of newly constructed modules have requires_grad=True by default\n",
    "        self.vgg16_fcn = vgg16.features\n",
    "        #self.vgg16_fcn.cuda()\n",
    "        self.lstm = torch.nn.LSTM(inputDim, outputDim, 1, True, True, 0.5);\n",
    "        self.fc = nn.Linear(outputDim, 1)\n",
    "        self.flatten_parameters()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.inputDim = inputDim\n",
    "    \n",
    "    def flatten_parameters(self):\n",
    "        self.lstm.flatten_parameters()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        newBatch = []\n",
    "        for t in range(len(x[1])):\n",
    "            newBatch.append(self.vgg16_fcn(x[:,t,:,:,:].float()))\n",
    "        grad = False\n",
    "        \n",
    "        #4 x 3 x (512 x 7 x 7)\n",
    "        vggOut = torch.stack(newBatch, 1).detach_()\n",
    "        #print(vggOut.shape)\n",
    "        \n",
    "        #4 x 3 x 25088\n",
    "        test = vggOut.view((4,3,-1))\n",
    "        #print(test.shape)\n",
    "        \n",
    "        #Output from LSTM 4 x 3 x 256\n",
    "        lstmOut, _ = self.lstm(test)\n",
    "        #print(lstmOut.shape)\n",
    "        \n",
    "        #Output from Fully Connected Layer 4 x 3 x 1\n",
    "        #fcOut = self.fc(lstmOut)\n",
    "        #print(fcOut)\n",
    "        #return fcOut\n",
    "        \n",
    "        sigOut = self.sigmoid(self.fc(lstmOut))\n",
    "        #print(sigOut)\n",
    "        return sigOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Not Using Cuda\n",
    "Extremely Slow\n",
    "\"\"\"\n",
    "model = MyModel(512*7*7, 256)\n",
    "batchOne = dataItem[0:4]\n",
    "batchTwo = dataItem[3:]\n",
    "#print(batchOne.shape)\n",
    "#print(batchTwo.shape)\n",
    "data = [batchOne, batchTwo]\n",
    "#Ground Truth\n",
    "scoreOnes = np.squeeze(scoreList[0:4])\n",
    "scoreTwo = np.squeeze(scoreList[3:])\n",
    "GT = [scoreOnes, scoreTwo]\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(len(data)):\n",
    "        x = Variable(torch.tensor(data[i], dtype=torch.float32))\n",
    "        y = Variable(torch.tensor(GT[i], dtype=torch.float32))\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        out = out.squeeze()\n",
    "        error = nn.functional.binary_cross_entropy(input=out, target=y, reduce=True)\n",
    "        error.backward()        \n",
    "        optimizer.step()\n",
    "    #if epoch % 5 == 0:\n",
    "        print('epoch %d:' % epoch, error.item())\n",
    "\"\"\"\n",
    "Not Using Cuda\n",
    "Extremely Slow\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0, epoch:99, error: 0.01907660998404026\n",
      "batch: 1, epoch:99, error: 0.09815434366464615\n",
      "batch: 0, epoch:199, error: 0.006939364597201347\n",
      "batch: 1, epoch:199, error: 0.04145383462309837\n",
      "batch: 0, epoch:299, error: 0.003786869579926133\n",
      "batch: 1, epoch:299, error: 0.024179920554161072\n",
      "batch: 0, epoch:399, error: 0.0024631733540445566\n",
      "batch: 1, epoch:399, error: 0.016475912183523178\n",
      "batch: 0, epoch:499, error: 0.0018162851920351386\n",
      "batch: 1, epoch:499, error: 0.012346982955932617\n",
      "batch: 0, epoch:599, error: 0.0014303672360256314\n",
      "batch: 1, epoch:599, error: 0.0098041370511055\n",
      "batch: 0, epoch:699, error: 0.0011693421984091401\n",
      "batch: 1, epoch:699, error: 0.008074057288467884\n",
      "batch: 0, epoch:799, error: 0.0009820455452427268\n",
      "batch: 1, epoch:799, error: 0.0068256244994699955\n",
      "batch: 0, epoch:899, error: 0.0008444422273896635\n",
      "batch: 1, epoch:899, error: 0.0058973548002541065\n",
      "batch: 0, epoch:999, error: 0.0007404612260870636\n",
      "batch: 1, epoch:999, error: 0.0051864939741790295\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Using Cuda\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "model = MyModel(512*7*7, 256).cuda()\n",
    "batchOne = dataItem[0:4]\n",
    "batchTwo = dataItem[3:]\n",
    "#print(batchOne.shape)\n",
    "#print(batchTwo.shape)\n",
    "data = [batchOne, batchTwo]\n",
    "#Ground Truth\n",
    "scoreOnes = np.squeeze(scoreList[0:4])\n",
    "scoreTwo = np.squeeze(scoreList[3:])\n",
    "GT = [scoreOnes, scoreTwo]\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(len(data)):\n",
    "        x = Variable(torch.tensor(data[i], dtype=torch.float32)).cuda()\n",
    "        y = Variable(torch.tensor(GT[i], dtype=torch.float32)).cuda()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        out = out.squeeze()\n",
    "        error = nn.functional.binary_cross_entropy(input=out, target=y, reduce=True).cuda()\n",
    "        error.backward()        \n",
    "        optimizer.step() \n",
    "        if (epoch+1) % 100 == 0:\n",
    "            print('batch: ' + str(i) + ', epoch:' + str(epoch) + ', error: ' + str(error.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
