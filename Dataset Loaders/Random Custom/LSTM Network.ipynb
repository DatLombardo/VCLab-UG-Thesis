{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "~~~| Custom.py Execution |~~~\n",
      "Loaded dataset\n",
      "~~~| Custom.py Complete |~~~\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU(inplace)\n",
       "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (3): ReLU(inplace)\n",
       "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (6): ReLU(inplace)\n",
       "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (8): ReLU(inplace)\n",
       "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (11): ReLU(inplace)\n",
       "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (13): ReLU(inplace)\n",
       "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (15): ReLU(inplace)\n",
       "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (18): ReLU(inplace)\n",
       "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (20): ReLU(inplace)\n",
       "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (22): ReLU(inplace)\n",
       "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (25): ReLU(inplace)\n",
       "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (27): ReLU(inplace)\n",
       "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (29): ReLU(inplace)\n",
       "  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "import Custom as CustomDataset\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\"\"\"\n",
    "Do not run this code block without cuda()\n",
    "\n",
    "Load in vgg16, \n",
    "\"\"\"\n",
    "vgg16 = models.vgg16(pretrained=True).cuda()\n",
    "#vgg16 = models.vgg16(pretrained=True)\n",
    "customDataloader = CustomDataset.main() #for dataloader\n",
    "\n",
    "for param in vgg16.parameters():\n",
    "    param.requires_grad = False\n",
    "    # Replace the last fully-connected layer\n",
    "    # Parameters of newly constructed modules have requires_grad=True by default\n",
    "vgg16_fcn = vgg16.features \n",
    "vgg16_fcn.cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataPoint(element, index):\n",
    "    scores = []\n",
    "    for frame in range(len(element['video'][index])):\n",
    "        video = element['video'][index]\n",
    "        #plt.imshow(video[frame].numpy())\n",
    "        #plt.show(block=False)\n",
    "        \n",
    "        #print(data['video'][seg][frame].shape)\n",
    "        #print(element['scores'][frame][index])\n",
    "        scores.append(int(element['scores'][frame][index]))\n",
    "    points = np.zeros((7,3), dtype=int)\n",
    "    frames = np.add(*np.indices((7, 3)))\n",
    "    if (1 in scores):\n",
    "        boundary = scores.index(1)\n",
    "        for i in range(7):\n",
    "            for j in range(3):\n",
    "                frames[i][j] = i + j\n",
    "                if (i + j == boundary):\n",
    "                    points[i][j] = 1\n",
    "    return points.tolist(), frames.tolist(), video, index\n",
    "\n",
    "def parseVideoMatrix(vid, positions):\n",
    "    vid = vid.numpy()\n",
    "    newData = np.zeros((7, 3, 3, 224,224))\n",
    "    count = 0\n",
    "    for i in positions:\n",
    "        frames = np.zeros((3, 3, 224, 224))\n",
    "        for j in range(len(i)):\n",
    "            #Models expect 3xHxW\n",
    "            #Current format before swaps, WxHx3\n",
    "            frames[j,...] = np.swapaxes(vid[i[j]], 0, 2)\n",
    "        newData[count,...] = frames\n",
    "        count += 1\n",
    "    return newData\n",
    "    \n",
    "def parseViewVids(vid, positions):\n",
    "    vid = vid.numpy()\n",
    "    newData = np.zeros((7, 3, 224, 224,3))\n",
    "    count = 0\n",
    "    for i in positions:\n",
    "        frames = np.zeros((3, 224, 224, 3))\n",
    "        for j in range(len(i)):\n",
    "            #Models expect 3xHxW\n",
    "            #Current format before swaps, WxHx3\n",
    "            frames[j,...] = vid[i[j]]\n",
    "        newData[count,...] = frames\n",
    "        count += 1\n",
    "    return newData\n",
    "\n",
    "def viewVideo(vid):\n",
    "    for i in vid:\n",
    "        for j in i:\n",
    "            plt.imshow(j)\n",
    "            plt.show(block=False)\n",
    "            \n",
    "\n",
    "\"\"\"\n",
    "Reading in data to get single batch for training\n",
    "\"\"\"\n",
    "for batch_i, data in enumerate(customDataloader): \n",
    "        for i in range(len(data['video'])):\n",
    "            currSegment = data['video'][i]\n",
    "            showFrame = data['video'][i][0]\n",
    "            #plt.imshow(showFrame.numpy())\n",
    "            #plt.show(block=False)\n",
    "            \n",
    "            batchData = data\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 3, 224, 224])\n",
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]]\n",
      "torch.Size([4, 3, 3, 224, 224])\n",
      "[[0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "scoreList, frameNums, vidData, index = getDataPoint(batchData, 3)\n",
    "dataItem = parseVideoMatrix(vidData, frameNums)\n",
    "\n",
    "#Can be commented out if not wanting to view\n",
    "#viewItem = parseViewVids(vidData, frameNums)\n",
    "#viewVideo(viewItem)\n",
    "#print(scoreList)\n",
    "#print(frameNums)\n",
    "\n",
    "dataItem = np.asarray(dataItem)\n",
    "dataItem = torch.tensor(dataItem)\n",
    "\"\"\"\n",
    "for elem in dataItem:\n",
    "    out = vgg16_fcn(elem.float().cuda())\n",
    "    print(out.shape)\n",
    "\"\"\"\n",
    "batchOne = dataItem[0:4]\n",
    "scoreOnes = np.squeeze(scoreList[0:4])\n",
    "batchTwo = dataItem[3:]\n",
    "scoreTwo = np.squeeze(scoreList[3:])\n",
    "print(batchOne.shape)\n",
    "print(scoreOnes)\n",
    "print(batchTwo.shape)\n",
    "print(scoreTwo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 3, 224, 224])\n",
      "torch.Size([4, 3, 3, 224, 224])\n",
      "torch.Size([4, 3, 224, 224])\n",
      "torch.Size([4, 3, 512, 7, 7])\n",
      "torch.Size([4, 3, 25088])\n",
      "torch.Size([4, 3, 256])\n",
      "torch.Size([4, 3])\n",
      "tensor([[ 0.1549,  0.2016,  0.1307],\n",
      "        [ 0.1839,  0.1291,  0.1011],\n",
      "        [ 0.1060,  0.0818, -0.0234],\n",
      "        [ 0.0690, -0.0328, -0.2472]], grad_fn=<SqueezeBackward0>)\n",
      "torch.Size([4, 3, 512, 7, 7])\n",
      "torch.Size([4, 3, 25088])\n",
      "torch.Size([4, 3, 256])\n",
      "torch.Size([4, 3])\n",
      "tensor([[ 0.0690, -0.0328, -0.2472],\n",
      "        [-0.0291, -0.2410, -0.2251],\n",
      "        [-0.2034, -0.2088, -0.1241],\n",
      "        [-0.1392, -0.0747, -0.0169]], grad_fn=<SqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, inputDim, outputDim):\n",
    "        super(MyModel, self).__init__()\n",
    "        vgg16 = models.vgg16(pretrained=True)\n",
    "        #vgg16 = models.vgg16(pretrained=True).cuda()\n",
    "        for param in vgg16.parameters():\n",
    "            param.requires_grad = False\n",
    "            # Replace the last fully-connected layer\n",
    "            # Parameters of newly constructed modules have requires_grad=True by default\n",
    "        self.vgg16_fcn = vgg16.features\n",
    "        #self.vgg16_fcn.cuda()\n",
    "        self.lstm = torch.nn.LSTM(inputDim, outputDim, 1, True, True, 0.5);\n",
    "        self.fc = nn.Linear(outputDim, 1)\n",
    "        self.flatten_parameters()\n",
    "    \n",
    "    def flatten_parameters(self):\n",
    "        self.lstm.flatten_parameters()\n",
    "        \n",
    "    def forward(self, inDim, x):\n",
    "        newBatch = []\n",
    "        for t in range(len(x[1])):\n",
    "            newBatch.append(self.vgg16_fcn(x[:,t,:,:,:].float()))\n",
    "        grad = False\n",
    "        \n",
    "        #4 x 3 x (512 x 7 x 7)\n",
    "        vggOut = torch.stack(newBatch, 1).detach_()\n",
    "        print(vggOut.shape)\n",
    "        \n",
    "        #4 x 3 x 25088\n",
    "        test = vggOut.view((4,3,-1))\n",
    "        print(test.shape)\n",
    "        \n",
    "        #Output from LSTM 4 x 3 x 256\n",
    "        lstmOut, _ = self.lstm(test)\n",
    "        print(lstmOut.shape)\n",
    "        \n",
    "        #Output from Fully Connected Layer 4 x 3 x 1\n",
    "        fcOut = self.fc(lstmOut)\n",
    "        #print(fcOut)\n",
    "        return fcOut\n",
    "                \n",
    "                \n",
    "model = MyModel(512*7*7, 256)\n",
    "print(batchOne.shape)\n",
    "print(batchTwo.shape)\n",
    "print(batchOne[:,0,:,:,:].shape)\n",
    "\n",
    "out = np.squeeze(model(512*7*7, batchOne))\n",
    "print(out.shape)\n",
    "print(out)\n",
    "out2 = np.squeeze(model(512*7*7, batchTwo))\n",
    "print(out2.shape)\n",
    "print(out2)\n",
    "\"\"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "USING SIGMOID\n",
    "\"\"\"\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, inputDim, outputDim):\n",
    "        super(MyModel, self).__init__()\n",
    "        vgg16 = models.vgg16(pretrained=True)\n",
    "        #vgg16 = models.vgg16(pretrained=True).cuda()\n",
    "        for param in vgg16.parameters():\n",
    "            param.requires_grad = False\n",
    "            # Replace the last fully-connected layer\n",
    "            # Parameters of newly constructed modules have requires_grad=True by default\n",
    "        self.vgg16_fcn = vgg16.features\n",
    "        #self.vgg16_fcn.cuda()\n",
    "        self.lstm = torch.nn.LSTM(inputDim, outputDim, 1, True, True, 0.5);\n",
    "        self.fc = nn.Linear(outputDim, 1)\n",
    "        self.flatten_parameters()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def flatten_parameters(self):\n",
    "        self.lstm.flatten_parameters()\n",
    "        \n",
    "    def forward(self, inDim, x):\n",
    "        newBatch = []\n",
    "        for t in range(len(x[1])):\n",
    "            newBatch.append(self.vgg16_fcn(x[:,t,:,:,:].float()))\n",
    "        grad = False\n",
    "        \n",
    "        #4 x 3 x (512 x 7 x 7)\n",
    "        vggOut = torch.stack(newBatch, 1).detach_()\n",
    "        print(vggOut.shape)\n",
    "        \n",
    "        #4 x 3 x 25088\n",
    "        test = vggOut.view((4,3,-1))\n",
    "        print(test.shape)\n",
    "        \n",
    "        #Output from LSTM 4 x 3 x 256\n",
    "        lstmOut, _ = self.lstm(test)\n",
    "        print(lstmOut.shape)\n",
    "        \n",
    "        #Output from Fully Connected Layer 4 x 3 x 1\n",
    "        #fcOut = self.fc(lstmOut)\n",
    "        #print(fcOut)\n",
    "        #return fcOut\n",
    "        \n",
    "        sigOut = self.sigmoid(self.fc(lstmOut))\n",
    "        print(sigOut)\n",
    "        return sigOut\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossFunction(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LossFunction, self).__init__()\n",
    "        loss = nn.BCELoss()\n",
    "    def forward(self, estimate, groundTruth):\n",
    "        return loss(estimate, groundTruth)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 512, 7, 7])\n",
      "torch.Size([4, 3, 25088])\n",
      "torch.Size([4, 3, 256])\n",
      "tensor([[[0.5313],\n",
      "         [0.5442],\n",
      "         [0.5598]],\n",
      "\n",
      "        [[0.5347],\n",
      "         [0.5545],\n",
      "         [0.5751]],\n",
      "\n",
      "        [[0.5419],\n",
      "         [0.5707],\n",
      "         [0.5713]],\n",
      "\n",
      "        [[0.5597],\n",
      "         [0.5624],\n",
      "         [0.5556]]], grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded while calling a Python object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-69b2dcfa262f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-4eec487a41cb>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, estimate, groundTruth)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroundTruth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroundTruth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "... last 2 frames repeated, from the frame below ...\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded while calling a Python object"
     ]
    }
   ],
   "source": [
    "model = MyModel(512*7*7, 256)\n",
    "#print(batchOne.shape)\n",
    "#print(batchTwo.shape)\n",
    "data = [batchOne, batchTwo]\n",
    "#Ground Truth\n",
    "scoreOnes = np.squeeze(scoreList[0:4])\n",
    "scoreTwo = np.squeeze(scoreList[3:])\n",
    "GT = [scoreOnes, scoreTwo]\n",
    "\n",
    "loss = LossFunction()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(len(data)):\n",
    "        out = np.squeeze(model(512*7*7, data[i]))\n",
    "        error = loss(out, GT[i])\n",
    "        optimizer.zero_grad()\n",
    "        error.backward()        \n",
    "        optimizer.step()\n",
    "    if epoch % 5 == 0:\n",
    "        print('epoch %d:' % epoch, error.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
